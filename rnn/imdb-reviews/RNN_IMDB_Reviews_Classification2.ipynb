{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN IMDB Reviews Classification",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z82c-Fcay0a3"
      },
      "source": [
        "## Stage 1: Install dependencies and setting up GPU environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoH0-SMEOy-j",
        "outputId": "410679db-970e-4dc6-b26e-4f0329d69ff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "!pip install numpy==1.16.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.16.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/bf/4981bcbee43934f0adb8f764a1e70ab0ee5a448f6505bd04a87a2fda2a8b/numpy-1.16.1-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 203kB/s \n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.16.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "Successfully installed numpy-1.16.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL3SBH6PzDwV"
      },
      "source": [
        "## Stage 2: Importing project dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynShOu8nNtFt"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dropout\n",
        "from tensorflow.keras.datasets import imdb"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw7-sPdOzf5l",
        "outputId": "8df29d0f-a2a4-403a-b4d2-584f3c75f75b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEjlM2EazOf0"
      },
      "source": [
        "## Stage 3: Dataset preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB0tNtXJzTfA"
      },
      "source": [
        "### Setting up dataset parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw6_KU24SrYK"
      },
      "source": [
        "number_of_words = 20000\n",
        "max_len = 100"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePywR8A4zaxT"
      },
      "source": [
        "### Loading the IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kCTV_hjOKmE"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=number_of_words)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZKDNoTKzi5w"
      },
      "source": [
        "### Padding all sequences to be the same length "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHcMNzv7Pd1s"
      },
      "source": [
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcxd--ESP3Rh"
      },
      "source": [
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xDMP44Zz0dU"
      },
      "source": [
        "### Setting up Embedding Layer parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGHQ2upgQIGj"
      },
      "source": [
        "vocab_size = number_of_words\n",
        "embed_size = 256\n",
        "input_shape_emb = (X_train.shape[1],)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG6LBKGnz7jT"
      },
      "source": [
        "## Step 4: Building a Recurrent Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2GHzwk6OMrV"
      },
      "source": [
        "def add_embeding_layer(model,vocab_size, embed_size, input_shape):\n",
        "  model.add(tf.keras.layers.Embedding(input_dim = vocab_size, output_dim = embed_size, input_shape=input_shape))\n",
        "  return model\n",
        "\n",
        "def add_lstm_layer(model, units=256, activation='tanh', drop_out_rate=0.2, return_sequences=True):\n",
        "  model.add(tf.keras.layers.LSTM(units=units, activation=activation, return_sequences = return_sequences))\n",
        "  model.add(Dropout(drop_out_rate))\n",
        "  return model\n",
        "\n",
        "def add_output_layer(model, units=1, activation='sigmoid'):\n",
        "  model.add(tf.keras.layers.Dense(units=units, activation=activation))\n",
        "  return model"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWqC0DXbO9FU"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model = add_embeding_layer(model,vocab_size, embed_size, input_shape)\n",
        "model = add_lstm_layer(model, units=256, activation='tanh', drop_out_rate=0.4, return_sequences=True)\n",
        "model = add_lstm_layer(model, units=128, activation='tanh', drop_out_rate=0.3, return_sequences=True)\n",
        "model = add_lstm_layer(model, units=64, activation='tanh', drop_out_rate=0.2, return_sequences=True)\n",
        "model = add_lstm_layer(model, units=32, activation='tanh', drop_out_rate=0.1, return_sequences=False)\n",
        "model = add_output_layer(model)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWcqM4Yr2ALS"
      },
      "source": [
        "### Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z9ACOXcRUUN"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiolKKO6RjVF",
        "outputId": "be0727f3-9bda-4097-b54d-6ec37791de22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_13 (Embedding)     (None, 100, 256)          5120000   \n",
            "_________________________________________________________________\n",
            "lstm_25 (LSTM)               (None, 100, 256)          525312    \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_26 (LSTM)               (None, 100, 128)          197120    \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 100, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm_27 (LSTM)               (None, 100, 64)           49408     \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 100, 64)           0         \n",
            "_________________________________________________________________\n",
            "lstm_28 (LSTM)               (None, 32)                12416     \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 5,904,289\n",
            "Trainable params: 5,904,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bPUvbfe2GJI"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FqUTA1CRpQ8",
        "outputId": "e423c419-bbfb-4a3e-9dff-1dba3cc96d4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        }
      },
      "source": [
        "model.fit(X_train, y_train, epochs=7, batch_size=64)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "391/391 [==============================] - 24s 62ms/step - loss: 0.4593 - accuracy: 0.7885\n",
            "Epoch 2/7\n",
            "391/391 [==============================] - 24s 62ms/step - loss: 0.2931 - accuracy: 0.8830\n",
            "Epoch 3/7\n",
            "391/391 [==============================] - 24s 62ms/step - loss: 0.2306 - accuracy: 0.9112\n",
            "Epoch 4/7\n",
            "391/391 [==============================] - 24s 62ms/step - loss: 0.1801 - accuracy: 0.9341\n",
            "Epoch 5/7\n",
            "391/391 [==============================] - 24s 62ms/step - loss: 0.1380 - accuracy: 0.9516\n",
            "Epoch 6/7\n",
            "391/391 [==============================] - 24s 62ms/step - loss: 0.1018 - accuracy: 0.9643\n",
            "Epoch 7/7\n",
            "391/391 [==============================] - 24s 62ms/step - loss: 0.0723 - accuracy: 0.9767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8f373e66a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wMo2wYpbCgb"
      },
      "source": [
        "### Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8kD_6q-RySO",
        "outputId": "45d3b084-757d-481a-b969-1f0d80ec6ffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_acurracy = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 11s 14ms/step - loss: 0.7851 - accuracy: 0.8201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0XnUtS-cEeI",
        "outputId": "cda8e905-362a-4123-9b31-e090ecb0d71e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Test accuracy: {}\".format(test_acurracy))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8201199769973755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN9QK49W3C29"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}