{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTYk-0EdutTA"
   },
   "source": [
    "# Cow vs Horse Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SuB_Hu4svEml"
   },
   "source": [
    "## Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P1UdD2g9NHGn"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-08692ddfd74d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "from google.colab import drive\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BBMBeW8KHbct"
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EZcdBctUD6D6"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XLfPDCjivPJ8"
   },
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WtNqejES2ko6"
   },
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9HEvjP40lx16"
   },
   "outputs": [],
   "source": [
    "rescale_default = 1./255\n",
    "shear_range_default=0.2\n",
    "zoom_range_default=0.2\n",
    "target_size_default=(64, 64)\n",
    "batch_size_default=32\n",
    "class_mode_default='binary'\n",
    "input_shape_default = [target_size_default[0], target_size_default[1], 3]\n",
    "main_path = '/content/drive/My Drive/Data Science/datasets/cows-and-horses'\n",
    "train_folder = main_path + '/train'\n",
    "test_folder = main_path + '/test'\n",
    "validaton_folder = main_path + '/validation'\n",
    "epochs_default = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wAdJPs8IvS-Q"
   },
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "  train_datagen = image.ImageDataGenerator(\n",
    "          rescale=rescale_default,\n",
    "          shear_range= shear_range_default,\n",
    "          zoom_range=zoom_range_default,\n",
    "          horizontal_flip=True)\n",
    "  train_set = train_datagen.flow_from_directory(\n",
    "          train_folder,\n",
    "          target_size=target_size_default,\n",
    "          batch_size=batch_size_default,\n",
    "          class_mode=class_mode_default)\n",
    "  \n",
    "  test_datagen = image.ImageDataGenerator(rescale=rescale_default)\n",
    "  test_set = test_datagen.flow_from_directory(\n",
    "        test_folder,\n",
    "        target_size=target_size_default,\n",
    "        batch_size=batch_size_default,\n",
    "        class_mode=class_mode_default)\n",
    "  return train_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FrbrH1D-3bWC"
   },
   "source": [
    "### Get Test And Train Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AA9sZBZXLgFU"
   },
   "outputs": [],
   "source": [
    "test_set, train_set = preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7PQAItbCvglE"
   },
   "source": [
    "## Init Model and Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4wgZHuhE5K9R"
   },
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w9T9YiZYvicS"
   },
   "outputs": [],
   "source": [
    "def get_cnn():\n",
    "  cnn = tf.keras.models.Sequential()\n",
    "  return cnn\n",
    "\n",
    "def get_layer(first=False):\n",
    "  if (first):\n",
    "    conv_layer = tf.keras.layers.Conv2D(\n",
    "      filters=32,\n",
    "      kernel_size = 3,\n",
    "      activation = 'relu'\n",
    "      )\n",
    "    return conv_layer\n",
    "  conv_layer = tf.keras.layers.Conv2D(\n",
    "      filters=32,\n",
    "      kernel_size = 3,\n",
    "      activation = 'relu',\n",
    "      input_shape = input_shape_default\n",
    "      )\n",
    "  return conv_layer\n",
    "\n",
    "def get_pooling():\n",
    "  max_pooling_layer = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)\n",
    "  return max_pooling_layer\n",
    "\n",
    "def flatten(cnn):\n",
    "  cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "def add_full_connection(cnn):\n",
    "  outputLayer = tf.keras.layers.Dense(units=128, activation='relu')\n",
    "  cnn.add(outputLayer)\n",
    "\n",
    "def add_output_layer(cnn):\n",
    "  outputLayer = tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "  cnn.add(outputLayer)\n",
    "\n",
    "def build_full_model(num_layers=2, shoudl_compile=True):\n",
    "  cnn = get_cnn()\n",
    "  for i in range(num_layers):\n",
    "    first = i == 0\n",
    "    layer = get_layer(first)\n",
    "    pooling = get_pooling()\n",
    "    cnn.add(layer)\n",
    "    cnn.add(pooling)\n",
    "  flatten(cnn)\n",
    "  add_full_connection(cnn)\n",
    "  add_output_layer(cnn)\n",
    "  if shoudl_compile:\n",
    "    cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  return cnn\n",
    "\n",
    "def train(cnn, train_set,test_set, epochs):\n",
    "  cnn.fit(x= train_set, validation_data= test_set, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gv13ZLzrwW_1"
   },
   "source": [
    "## Build, Training and Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VLs8LnSfwdCT"
   },
   "outputs": [],
   "source": [
    "cnn = build_full_model()\n",
    "train(cnn, train_set,test_set, epochs_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szGWKZ70wdvl"
   },
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hxBqoUyowg4K"
   },
   "outputs": [],
   "source": [
    "def predict_item(model, image_path, target_size):\n",
    "  image_predict = image.load_img(image_path, target_size= target_size)\n",
    "  image_predict = image.img_to_array(image_predict)\n",
    "  image_predict = np.expand_dims(image_predict,axis=0)  # Convert single image to a batch.\n",
    "  predictions = model.predict(image_predict)\n",
    "  return predictions\n",
    "\n",
    "def predict_class(train_set, predictions):\n",
    "  indices = train_set.class_indices\n",
    "  reverse_indices = {}\n",
    "  for x, y in indices.items():\n",
    "    reverse_indices[str(y)] = x\n",
    "    idx = int(predictions[0][0])\n",
    "  return reverse_indices[str(idx)]\n",
    "\n",
    "def predict_many(model, train_set, folder_path, target_size, expected_class):\n",
    "  images_paths = glob.glob(folder_path)\n",
    "  predictions_list = []\n",
    "  for image_path in images_paths:\n",
    "    predictions = predict_item(model, image_path, target_size)\n",
    "    class_predicted = predict_class(train_set, predictions)\n",
    "    prediction = {\n",
    "        'expected':expected_class.lower(),\n",
    "        'found': class_predicted.lower(),\n",
    "        'got_it_rigth': expected_class.lower() == class_predicted.lower()\n",
    "        }\n",
    "    predictions_list.append(prediction)\n",
    "  return predictions_list\n",
    "\n",
    "def print_predictions(predictions_list):\n",
    "  rights = filter(lambda item: item['got_it_rigth'] == True, predictions_list)\n",
    "  _percent_right = len(list(rights)) / len(predictions_list)\n",
    "  print(\"% righs {}\".format(_percent_right * 100))\n",
    "  for idx, item in enumerate(predictions_list):\n",
    "    print(\"#{} Expected: {} - Found: {} - Right? {}\".format(idx,item['expected'], item['found'], item['got_it_rigth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G8aoTBFIP7Tr"
   },
   "outputs": [],
   "source": [
    "validation_cows = validaton_folder + '/cows/*'\n",
    "validation_horses = validaton_folder + '/horses/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qaXD08RhYw25"
   },
   "outputs": [],
   "source": [
    "cows_result = predict_many(cnn, train_set, validation_cows, target_size_default,'cows')\n",
    "horses_result = predict_many(cnn, train_set, validation_horses, target_size_default,'horses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZEFX1FfGRMtD"
   },
   "outputs": [],
   "source": [
    "print_predictions(cows_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NqzPaWTTi78S"
   },
   "outputs": [],
   "source": [
    "print_predictions(horses_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WeXrlSQCp4bE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "animals_classifier",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
